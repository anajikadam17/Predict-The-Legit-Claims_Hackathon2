{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "Insurance companies take risks over customers. Risk management is a very important aspect of the insurance industry. Insurers consider every quantifiable factor to develop profiles of high and low insurance risks. Insurers collect vast amounts of information about policyholders and analyze the data.\n",
    "\n",
    "As a Data scientist in an insurance company, you need to analyze the available data and predict whether to sanction the insurance or not.\n",
    "\n",
    "### Dataset Description\n",
    "A zipped file containing train, test and sample submission files are given. The training dataset consists of data corresponding to 52310 customers and the test dataset consists of 22421 customers. Following are the features of the dataset\n",
    "\n",
    "Target: Claim Status (Claim)\n",
    "\n",
    "Name of agency (Agency)\n",
    "\n",
    "Type of travel insurance agencies (Agency.Type)\n",
    "\n",
    "Distribution channel of travel insurance agencies (Distribution.Channel)\n",
    "\n",
    "Name of the travel insurance products (Product.Name)\n",
    "\n",
    "Duration of travel (Duration)\n",
    "\n",
    "Destination of travel (Destination)\n",
    "\n",
    "Amount of sales of travel insurance policies (Net.Sales)\n",
    "\n",
    "The commission received for travel insurance agency (Commission)\n",
    "\n",
    "Age of insured (Age)\n",
    "\n",
    "The identification record of every observation (ID)\n",
    "\n",
    "Evaluation Metric\n",
    "The evaluation metric for this task will be precision_score. Read up about it more here.\n",
    "\n",
    "### Submission Format\n",
    "The user has to submit a csv file with the ID and Claim label. Sample submission file has been given to you. You can refer the sample submission file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outlier and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier ,RandomForestClassifier ,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score ,mean_squared_error,accuracy_score,classification_report,roc_curve,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns',None)\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data is:  (52310, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>61</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4245</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>4</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9251</td>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>26</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>15</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8840</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>15</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID Agency    Agency Type Distribution Channel  \\\n",
       "0  2010    EPX  Travel Agency               Online   \n",
       "1  4245    EPX  Travel Agency               Online   \n",
       "2  9251    CWT  Travel Agency               Online   \n",
       "3  4754    EPX  Travel Agency               Online   \n",
       "4  8840    EPX  Travel Agency               Online   \n",
       "\n",
       "                      Product Name  Duration  Destination  Net Sales  \\\n",
       "0                Cancellation Plan        61  PHILIPPINES       12.0   \n",
       "1                Cancellation Plan         4     MALAYSIA       17.0   \n",
       "2  Rental Vehicle Excess Insurance        26     THAILAND       19.8   \n",
       "3         2 way Comprehensive Plan        15    HONG KONG       27.0   \n",
       "4         2 way Comprehensive Plan        15     MALAYSIA       37.0   \n",
       "\n",
       "   Commision (in value)  Age  Claim  \n",
       "0                  0.00   41      0  \n",
       "1                  0.00   35      0  \n",
       "2                 11.88   47      0  \n",
       "3                  0.00   48      0  \n",
       "4                  0.00   36      0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/train.csv'\n",
    "\n",
    "# Load the dataframe\n",
    "data = pd.read_csv(path,delimiter=',')\n",
    "\n",
    "# Remove the Id column from the dataset\n",
    "# data.drop('Id',axis=1,inplace=True)\n",
    "\n",
    "print('Shape of the data is: ',data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>61</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>4</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>26</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>15</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>15</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Agency    Agency Type Distribution Channel                     Product Name  \\\n",
       "0    EPX  Travel Agency               Online                Cancellation Plan   \n",
       "1    EPX  Travel Agency               Online                Cancellation Plan   \n",
       "2    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "3    EPX  Travel Agency               Online         2 way Comprehensive Plan   \n",
       "4    EPX  Travel Agency               Online         2 way Comprehensive Plan   \n",
       "\n",
       "   Duration  Destination  Net Sales  Commision (in value)  Age  Claim  \n",
       "0        61  PHILIPPINES       12.0                  0.00   41      0  \n",
       "1         4     MALAYSIA       17.0                  0.00   35      0  \n",
       "2        26     THAILAND       19.8                 11.88   47      0  \n",
       "3        15    HONG KONG       27.0                  0.00   48      0  \n",
       "4        15     MALAYSIA       37.0                  0.00   36      0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing ID column\n",
    "data.drop(columns=['ID'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data['Duration'] < 0\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Duration'] < 0, 'Duration'] = data['Duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data['Duration'] < 0\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Target\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# Function that auto encodes any dataframe column of type category or object.\n",
    "def dummyEncode(dataset):\n",
    "        \n",
    "        columnsToEncode = list(dataset.select_dtypes(include=['category','object']))\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                dataset[feature] = le.fit_transform(dataset[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return dataset\n",
    "data = dummyEncode(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# split into 70:30 ration \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (36617, 9)\n",
      "Number transactions y_train dataset:  (36617,)\n",
      "Number transactions X_test dataset:  (15693, 9)\n",
      "Number transactions y_test dataset:  (15693,)\n"
     ]
    }
   ],
   "source": [
    "# describes info about train and test set \n",
    "print(\"Number transactions X_train dataset: \", X_train.shape) \n",
    "print(\"Number transactions y_train dataset: \", y_train.shape) \n",
    "print(\"Number transactions X_test dataset: \", X_test.shape) \n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'UNITED STATES'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-07189dde8804>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# train the model on train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1220\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'UNITED STATES'"
     ]
    }
   ],
   "source": [
    "# logistic regression object \n",
    "lr = LogisticRegression() \n",
    "  \n",
    "# train the model on train set \n",
    "lr.fit(X_train, y_train.ravel()) \n",
    "  \n",
    "predictions = lr.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression() \n",
    "lr1.fit(X_train_res, y_train_res.ravel()) \n",
    "predictions = lr1.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply near miss \n",
    "from imblearn.under_sampling import NearMiss \n",
    "nr = NearMiss() \n",
    "  \n",
    "X_train_miss, y_train_miss = nr.fit_sample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape)) \n",
    "print('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape)) \n",
    "  \n",
    "print(\"After Undersampling, counts of label '1': {}\".format(sum(y_train_miss == 1))) \n",
    "print(\"After Undersampling, counts of label '0': {}\".format(sum(y_train_miss == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on train set \n",
    "lr2 = LogisticRegression() \n",
    "lr2.fit(X_train_miss, y_train_miss.ravel()) \n",
    "predictions = lr2.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to detect outliers in every feature\n",
    "def detect_outliers(dataframe):\n",
    "    cols = list(dataframe)\n",
    "    outliers = pd.DataFrame(columns=['Feature','Number of Outliers','Percentage','Fence Low','Fence High'])\n",
    "    \n",
    "    for column in cols:\n",
    "        if column in dataframe.select_dtypes(include=np.number).columns:\n",
    "            # first quartile (Q1)\n",
    "            q1 = dataframe[column].quantile(0.25) \n",
    "            \n",
    "            # third quartile (Q3)\n",
    "            q3 = dataframe[column].quantile(0.75)\n",
    "            \n",
    "            # IQR\n",
    "            iqr = q3 - q1\n",
    "            \n",
    "            fence_low = q1 - (1.5*iqr)\n",
    "            fence_high = q3 + (1.5*iqr)\n",
    "            outliers = outliers.append({'Feature':column,\n",
    "                                        'Number of Outliers':dataframe.loc[(dataframe[column] < fence_low) \n",
    "                                                                           | (dataframe[column] > fence_high)]\n",
    "                                        .shape[0], 'Percentage':(dataframe.loc[(dataframe[column] < fence_low) | (dataframe[column] > fence_high)].shape[0]/len(dataframe))*100,\n",
    "                                       'Fence Low': fence_low, 'Fence High': fence_high},\n",
    "                                       ignore_index=True)\n",
    "    return outliers\n",
    "temp = detect_outliers(X)\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "# Function to treat outliers \n",
    "def treat_outliers(dataframe):\n",
    "    cols = list(dataframe)\n",
    "    for col in cols:\n",
    "        if col in dataframe.select_dtypes(include=np.number).columns:\n",
    "            dataframe[col] = winsorize(dataframe[col], limits=[0.05, 0.1],inclusive=(True, True))\n",
    "    \n",
    "    return dataframe    \n",
    "\n",
    "\n",
    "df = treat_outliers(X)\n",
    "\n",
    "# Checking for outliers after applying winsorization\n",
    "detect_outliers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Treat Skewness\n",
    "import scipy.stats as scs\n",
    "\n",
    "features = []\n",
    "skewness = []\n",
    "for i in X.select_dtypes(include=np.number).columns:\n",
    "    features.append(i)\n",
    "    skewness.append(scs.skew(X[i]))\n",
    "skewed = pd.DataFrame({'Features':features,'Skewness':skewness})\n",
    "\n",
    "# If skewness is greater than 1 the feature is highly positively skewed\n",
    "positively_skewed_variables = skewed[(skewed['Skewness']>1)]\n",
    "\n",
    "# If the skewness is less than -1 the feature is highly negatively skewed.\n",
    "negatively_skewed_variables = skewed[(skewed['Skewness']<-1)]\n",
    "\n",
    "print('Positively Skewed Features \\n',positively_skewed_variables)\n",
    "print('*'*50)\n",
    "print('Negatively Skewed Features \\n',negatively_skewed_variables) \n",
    "\n",
    "for i in positively_skewed_variables['Features']:\n",
    "     X[i] = np.log1p(X[i])\n",
    "# Let's remove the skewness in the positively skewed variables by using a log transform\n",
    "# for i in positively_skewed_variables['Features']:\n",
    "#     X[i] = np.log1p(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the skewness in the positively skewed variables by using a log transform\n",
    "for i in positively_skewed_variables['Features']:\n",
    "     X[i] = np.log1p(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers after applying winsorization\n",
    "detect_outliers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Class Imbalance\n",
    "def class_imbalance(target):\n",
    "    class_values = (target.value_counts()/target.value_counts().sum())*100\n",
    "    return class_values\n",
    "\n",
    "class_imbalance(data['Claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# Function that auto encodes any dataframe column of type category or object.\n",
    "def dummyEncode(dataset):\n",
    "        \n",
    "        columnsToEncode = list(dataset.select_dtypes(include=['category','object']))\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                dataset[feature] = le.fit_transform(dataset[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return dataset\n",
    "data = dummyEncode(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Target\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forrest(dataframe,target):\n",
    "    \n",
    "    x_train,x_val,y_train,y_val = train_test_split(dataframe,target, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Applying Smote on train data for dealing with class imbalance\n",
    "    smote = SMOTE(kind='regular')\n",
    "    X_sm, y_sm =  smote.fit_sample(x_train, y_train)\n",
    "    \n",
    "    global rfc\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(x_train, y_train)\n",
    "    y_pred=rfc.predict(x_val)\n",
    "    precision=precision_score(y_val,y_pred)\n",
    "    return precision\n",
    "\n",
    "#trainning\n",
    "precision = random_forrest(X,y)    \n",
    "print('score is:',precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#testing function\n",
    "def prediction(test):\n",
    "    y_pred = rfc.predict(test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "test=pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Storing the Id column\n",
    "Id = test[['ID']]\n",
    "\n",
    "# Preprocessed Test File\n",
    "test.drop('ID',1,inplace=True)\n",
    "test.head()\n",
    "#label encoder\n",
    "test = dummyEncode(test)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on test file\n",
    "y_pred = pd.DataFrame(prediction(test),columns=['Claim']) \n",
    "print(y_pred['Claim'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#predicting on test file\n",
    "y_pred = pd.DataFrame(prediction(test),columns=['Claim']) \n",
    "print(y_pred['Claim'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
